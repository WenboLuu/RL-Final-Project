method: bayes  # Bayesian optimization
metric:
  name: Reward/Eval
  goal: maximize
parameters:
  env_name:
    values: ["ALE/Pong-v5"]
  max_episode_steps:
    distribution: int_uniform
    min: 500
    max: 2000
  num_training_steps:
    values: [2e6]
  num_envs:
    values: [5, 10, 20]
  batch_size:
    values: [16, 32, 64]
  learning_rate:
    distribution: uniform
    min: 1e-5
    max: 1e-3
  gamma:
    values: [0.99]
  target_update_freq:
    distribution: int_uniform
    min: 2000
    max: 20000
  memory_size:
    values: [200000]
  epsilon_start:
    values: [1.0]
  epsilon_end:
    distribution: uniform
    min: 0.01
    max: 0.25
  epsilon_decay:
    distribution: uniform
    min: 1e-6
    max: 1e-4
  frame_skip:
    values: [4]
  eval_interval:
    values: [10000]
  num_eval_episodes:
    distribution: int_uniform
    min: 1
    max: 20
  eps_eval:
    values: [0.05]
  input_mode:
    values: ["rgb", "grayscale"]